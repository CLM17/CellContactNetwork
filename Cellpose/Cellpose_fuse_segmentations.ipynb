{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "representative-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** TORCH CUDA version installed and working. **\n",
      ">>> GPU activated? 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os, sys\n",
    "from urllib.parse import urlparse\n",
    "from skimage import io\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from cellpose import models\n",
    "\n",
    "use_GPU = models.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smoking-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_fused_image(fused, patch_height=512, patch_width=512, overlap=256):\n",
    "    \n",
    "    '''\n",
    "    This function makes the fused image larger s.t. an integer number of\n",
    "    patches fits into it.\n",
    "    \n",
    "    INPUTS\n",
    "    ------\n",
    "        fused (np array)\n",
    "        Fused (whole well) image.\n",
    "        \n",
    "        overlap (int)\n",
    "        Overlap of subimages in pixels. Default is 100.\n",
    "        \n",
    "        patch_width, patch_height\n",
    "        Size of patches. Default is 512.\n",
    "        \n",
    "    OUTPUTS\n",
    "    -------\n",
    "        new_fused (np array)\n",
    "        Enlarged fused image.\n",
    "        \n",
    "        patch_locations (list with 2 elements)\n",
    "        patch_locations[0] is a numpy array with the y-coordinates of the subimages in pixels.\n",
    "        patch_locations[1] is a numpy array with the x-coordinates of the subimages in pixels.\n",
    "    '''\n",
    "    \n",
    "    [m,n] = [patch_height, patch_width]\n",
    "    [M,N,C] = np.shape(fused)\n",
    "    \n",
    "    num_m = np.ceil((M - m) / (m - overlap) + 1).astype(int) # number of patches on y-axis\n",
    "    num_n = np.ceil((N - n) / (n - overlap) + 1).astype(int) # number of patches on x-axis\n",
    "\n",
    "    new_M = (num_m - 1) * (m - overlap) + m # new fused image height\n",
    "    new_N = (num_n - 1) * (n - overlap) + n # new fused image width\n",
    "    \n",
    "    new_fused = np.zeros([new_M,new_N,C], dtype='uint8')\n",
    "    new_fused[0:M,0:N,:] = fused\n",
    "    \n",
    "    patch_locations = []\n",
    "    patch_locations.append(np.arange(0,new_M-m+1,m-overlap)) # y-locations of patches (in pixels)\n",
    "    patch_locations.append(np.arange(0,new_N-n+1,n-overlap)) # x-locations of patches (in pixels)\n",
    "    \n",
    "    return [new_fused, patch_locations]\n",
    "\n",
    "def fused_to_patches(fused, patch_locations, patch_height=512, patch_width=512):\n",
    "    '''\n",
    "    This function takes as input an (enlarged) fused image.\n",
    "    It outputs a list of patches which are ordered in a column-to-column grid.\n",
    "    The locations of the patches in the fused image are specified by patch_locations.\n",
    "    '''\n",
    "    [n,m] = [patch_height, patch_width]\n",
    "    patch_list = []\n",
    "    for c_n in patch_locations[1]:     # c_n is n-coordinate in pixels\n",
    "        for c_m in patch_locations[0]: # c_m is m-coordinate in pixels\n",
    "            patch = fused[c_m:c_m+m,c_n:c_n+n,:]\n",
    "            patch_list.append(patch)\n",
    "    \n",
    "    return patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marked-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(mask):\n",
    "    '''\n",
    "    This function finds the edges of labeled objects in the mask.\n",
    "    '''\n",
    "\n",
    "    padded_mask = np.pad(mask,1,mode='edge')\n",
    "\n",
    "    center = padded_mask[1:-1,1:-1]\n",
    "    up = padded_mask[0:-2,1:-1]\n",
    "    up_left = padded_mask[0:-2,0:-2]\n",
    "    left = padded_mask[1:-1,0:-2]\n",
    "\n",
    "    compare = np.array((center!=up,center!=up_left,center!=left))\n",
    "    edges = np.logical_or.reduce(compare)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def split_cells_on_mask(mask):\n",
    "    '''\n",
    "    This function separates objects on the mask\n",
    "    based on edges.\n",
    "    '''\n",
    "    edges = find_edges(mask)\n",
    "    compare = np.array((mask > 0, ~edges))\n",
    "    segmented_mask = np.logical_and.reduce(compare)\n",
    "    \n",
    "    return segmented_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "horizontal-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_img_similarity(img1, img2):\n",
    "    '''\n",
    "    This function calculates what percentage of\n",
    "    img1 and img2 are the same.\n",
    "    Img1 and img2 are boolean images.\n",
    "    '''\n",
    "    equal_pixels = np.logical_and(img1,img2)\n",
    "    return np.sum(equal_pixels) / min([np.sum(img1), np.sum(img2)])\n",
    "\n",
    "def find_cell_values_which_overlap(cell_on_overlap, combined_overlap, similarity_threshold):\n",
    "    '''\n",
    "    This function finds which cells on the combined_overlap image\n",
    "    overlap with the boolean image cell_on_overlap.\n",
    "    '''\n",
    "    overlapping_cell_values = cell_on_overlap * combined_overlap\n",
    "    unique = np.unique(overlapping_cell_values)\n",
    "    values_with_sufficient_overlap = []\n",
    "    \n",
    "    # loop through cells which overlap with the cell on the egde\n",
    "    # and calculate similarity\n",
    "    for overlapping_value in unique[1:]:\n",
    "        cell_on_mask = (combined_overlap==overlapping_value)\n",
    "        if calculate_img_similarity(cell_on_mask, cell_on_overlap) > similarity_threshold:\n",
    "            values_with_sufficient_overlap.append(overlapping_value)\n",
    "            \n",
    "    return values_with_sufficient_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharing-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_overlapping_cells(values_on_edge, patch_ol, combined_ol, similarity_threshold):\n",
    "    '''\n",
    "    This function stores which cells on combined_ol overlap with the\n",
    "    cells in the edge region of patch_ol (in a dictionary).\n",
    "    Keys in the 'overlap_dict' dictionary are the values of cells which lie\n",
    "    in the edge region of patch_ol.\n",
    "    Corresponding values are the cells on combined_ol which sufficiently\n",
    "    overlap with the cells.\n",
    "    Example: overlap_dict = {23: [34,45]}\n",
    "             means that there is a cell (nr 23) on path_ol in the edge region.\n",
    "             It overlaps with cells 34 and 45. These are probably two half cells.\n",
    "    '''\n",
    "    # Initialise dictionary to store old and new values\n",
    "    overlap_dict = {}\n",
    "    # Collect values to be removed in the replace dictionary\n",
    "    for value in values_on_edge:\n",
    "        cell_shape = (patch_ol == value)\n",
    "        values_overlapping = find_cell_values_which_overlap(cell_shape, combined_ol, similarity_threshold)\n",
    "        overlap_dict[value] = values_overlapping   \n",
    "        \n",
    "    return overlap_dict\n",
    "\n",
    "def replace_overlapping_cells(overlap_dict, patch_ol, combined_ol, max_value):\n",
    "    '''\n",
    "    This function replaces cells on the edge of combined_ol with \n",
    "    overlapping cells on the edge of patch_ol.\n",
    "    The cells on patch_ol are correctly predicted, so they should\n",
    "    replace the wrongly predicted cells on combined_ol.\n",
    "    '''\n",
    "    combined_ol_new = np.copy(combined_ol)\n",
    "    for value, values_to_remove in overlap_dict.items():\n",
    "        # remove value which overlaps with a cell on patch_ol\n",
    "        for old_value in values_to_remove:\n",
    "            combined_ol_new[np.where(combined_ol_new==old_value)] = 0\n",
    "        # add the cells on mask_ol to the image\n",
    "        if len(values_to_remove) > 0:     \n",
    "            max_value = max_value + 1\n",
    "            combined_ol_new[np.where(patch_ol==value)] = max_value\n",
    "            \n",
    "    return combined_ol_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sixth-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_patches(patch1, patch2, patch_ol, edge_thickness, similarity_threshold, axis):\n",
    "    \n",
    "    '''\n",
    "    This function aligns patch1 and patch2 based on the overlap patch_ol.\n",
    "    '''\n",
    "    \n",
    "    m,n = np.shape(patch1)\n",
    "    edge_size = int(edge_thickness/2)\n",
    "    \n",
    "    # Increase cell values on patch2 with the max value of patch1\n",
    "    patch2[np.where(patch2>0)] = patch2[np.where(patch2>0)] + np.max(patch1)\n",
    "    # Get max value (values of new overlapping cells are always larger than max_value)\n",
    "    max_value = np.max(patch2)\n",
    "    \n",
    "    # Get a list of cells that lie on the edge region of the overlapping patch (values_on_edge)\n",
    "    # Create combined overlap by pasting the 2 patches together (combined_ol)\n",
    "    if (axis==0):\n",
    "        center = int(m / 2)\n",
    "        values_on_edge = np.unique( patch_ol[center-edge_size:center+edge_size+1,:] )\n",
    "        combined_ol = np.concatenate([patch1[center:m,:],patch2[0:center,:]],axis=0)\n",
    "    elif (axis==1):\n",
    "        center = int(n / 2)\n",
    "        values_on_edge = np.unique( patch_ol[:,center-edge_size:center+edge_size+1] )\n",
    "        combined_ol = np.concatenate([patch1[:,center:n],patch2[:,0:center]],axis=1)\n",
    "    else:\n",
    "        raise ValueError('Invalid choice for axis. Please choose either 0 or 1.')\n",
    "    \n",
    "    # Remove 0 (=background) from the list\n",
    "    values_on_edge = np.delete(values_on_edge, np.where(values_on_edge==0))    \n",
    "\n",
    "    # Find overlapping cells \n",
    "    overlap = store_overlapping_cells(values_on_edge, patch_ol, combined_ol, similarity_threshold)\n",
    "    combined_ol_new = replace_overlapping_cells(overlap, patch_ol, combined_ol, max_value)\n",
    "    \n",
    "    # Update patches\n",
    "    if (axis==0):\n",
    "        patch1_new = np.concatenate([patch1[0:center,:],combined_ol_new[0:center,:]],axis=0)\n",
    "        patch2_new = np.concatenate([combined_ol_new[center:m,:],patch2[center:m,:]],axis=0)\n",
    "    elif (axis==1):\n",
    "        patch1_new = np.concatenate([patch1[:,0:center],combined_ol_new[:,0:center]],axis=1)\n",
    "        patch2_new = np.concatenate([combined_ol_new[:,center:n],patch2[:,center:n]],axis=1)\n",
    "    \n",
    "    return patch1_new, patch2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moral-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_cells(fused_mask, cell_size_threshold):\n",
    "    '''\n",
    "    This function removes cells smaller than cell_size_threshold.\n",
    "    '''\n",
    "    # Separate cells on fused mask\n",
    "    separated_cells = split_cells_on_mask(fused_mask)\n",
    "\n",
    "    # Remove cells smaller than cell_size_threshold\n",
    "    label_objects, nb_labels = ndi.label(separated_cells)\n",
    "    sizes = np.bincount(label_objects.ravel())\n",
    "    mask_sizes = sizes > cell_size_threshold\n",
    "    mask_sizes[0] = 0\n",
    "    filtered_cells = mask_sizes[label_objects]\n",
    "\n",
    "    # Label again\n",
    "    filtered_fused_mask, nb_labels = ndi.label(filtered_cells)\n",
    "    \n",
    "    return filtered_fused_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_columns(mask_list, patch_locations, edge_thickness, similarity_threshold):\n",
    "\n",
    "    num_patches_mm = np.size(patch_locations[0])\n",
    "    num_patches_nn = np.size(patch_locations[1])\n",
    "    overlapping_columns = []\n",
    "\n",
    "    # loop over all columns\n",
    "    for nn in range(0, num_patches_nn):\n",
    "\n",
    "        print('Aligning patches in column ',nn,'...')\n",
    "        patches_in_column = []\n",
    "\n",
    "        # loop over rows in steps of 2 (avoid the last patch in column)\n",
    "        for mm in range(0,num_patches_mm-1,2):\n",
    "\n",
    "            # Get patch1, patch2 and patch_ol\n",
    "            patch_nr = nn * num_patches_mm + mm\n",
    "            if mm==0: # if we are at the top of the column\n",
    "                patch1 = np.copy(mask_list[patch_nr])        # patch1 (upper patch) is new patch from patch_list\n",
    "                patches_in_column.append(patch1)\n",
    "            else:\n",
    "                patch1 = np.copy(patches_in_column[-1])       # patch1 (upper patch) is previously processed patch\n",
    "            patch2 = np.copy(mask_list[patch_nr + 2])         # patch2 is lower patch\n",
    "            patch_ol = np.copy(mask_list[patch_nr + 1])       # patch_ol is overlapping patch\n",
    "\n",
    "            # Align patch1 and patch2 using overlap\n",
    "            patch1_new,patch2_new = align_patches(patch1, patch2, patch_ol, edge_thickness, similarity_threshold, axis=0)\n",
    "            patches_in_column[-1] = patch1_new     # overwrite first patch\n",
    "            patches_in_column.append(patch2_new)   # append new patch\n",
    "\n",
    "        # Combine patches into a column\n",
    "        aligned_patches = np.concatenate(patches_in_column,axis=0)\n",
    "        overlapping_columns.append(aligned_patches)\n",
    "        \n",
    "    return overlapping_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advanced-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_overlapping_columns(overlapping_columns, edge_thickness, similarity_threshold):\n",
    "    \n",
    "    num_columns = len(overlapping_columns)\n",
    "    aligned_columns = []\n",
    "\n",
    "    # loop over columns in steps of 2 (avoiding the last one)\n",
    "    for nn in range(0,num_columns-1,2):\n",
    "\n",
    "        print('Aligning columns ', nn, ' and ',nn+2,'...')\n",
    "\n",
    "        # Get patch1, patch2 and patch_ol\n",
    "        if nn==0:\n",
    "            patch1 = np.copy(overlapping_columns[nn])  # first column\n",
    "            aligned_columns.append(patch1)\n",
    "        else:\n",
    "            patch1 = np.copy(aligned_columns[-1])      # left column\n",
    "        patch2 = np.copy(overlapping_columns[nn+2])    # right column\n",
    "        patch_ol = np.copy(overlapping_columns[nn+1])  # overlapping column\n",
    "\n",
    "        # Align patch1 and patch2 using overlap\n",
    "        patch1_new,patch2_new = align_patches(patch1, patch2, patch_ol, edge_thickness, similarity_threshold, axis=1)\n",
    "\n",
    "        aligned_columns[-1] = patch1_new    # overwrite left column\n",
    "        aligned_columns.append(patch2_new)  # append right column\n",
    "        \n",
    "    return aligned_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "linear-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_fused_image_with_cellpose(path_to_well_folder, well, diameter, channels,\n",
    "                                      edge_thickness=60, similarity_threshold=0.8,\n",
    "                                      cell_size_threshold=100, patch_height=512, patch_width=512):\n",
    "\n",
    "    overlap = int(512/2)\n",
    "\n",
    "    # Read fused image and enlarge it\n",
    "    fused_path = os.path.join(path_to_well_folder, well+'_fused_RGB.tif')\n",
    "    fused = io.imread(fused_path)\n",
    "    [M,N,C] = np.shape(fused)\n",
    "    [new_fused, patch_locations] = enlarge_fused_image(fused, patch_height=patch_height, patch_width=patch_width, overlap=overlap)\n",
    "\n",
    "    # Make a list of patches\n",
    "    patch_list = fused_to_patches(new_fused, patch_locations)\n",
    "    print('Number of patches to predict: %d'%len(patch_list))\n",
    "\n",
    "    # Predict patches with cellpose\n",
    "    model = models.Cellpose(gpu=use_GPU, model_type='cyto')\n",
    "    mask_list, flows, styles, diams = model.eval(patch_list, diameter=diameter, flow_threshold=None, channels=channels)\n",
    "\n",
    "    # Align vertical patches into overlapping columns\n",
    "    overlapping_columns = create_overlapping_columns(mask_list, patch_locations, edge_thickness, similarity_threshold)\n",
    "    # Align overlapping columns\n",
    "    aligned_columns = align_overlapping_columns(overlapping_columns, edge_thickness, similarity_threshold)\n",
    "\n",
    "    # Combine overlapping columns into a fused_mask\n",
    "    fused_mask = np.concatenate(aligned_columns, axis=1)\n",
    "    fused_mask = fused_mask[0:M,0:N]\n",
    "\n",
    "    # Remove cells smaller than cell_size_threshold\n",
    "    filtered_fused_mask = remove_small_cells(fused_mask, cell_size_threshold)\n",
    "\n",
    "    return filtered_fused_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arctic-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subimages to predict: 961\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 961 image(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:234: UserWarning: chan to seg' has value range of ZERO\n",
      "  warnings.warn(\"chan to seg' has value range of ZERO\")\n",
      "C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:236: UserWarning: 'chan2 (opt)' has value range of ZERO, can instead set chan2 to 0\n",
      "  warnings.warn(\"'chan2 (opt)' has value range of ZERO, can instead set chan2 to 0\")\n",
      "C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:186: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  X = (X - np.percentile(X, 1)) / (np.percentile(X, 99) - np.percentile(X, 1))\n",
      "C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = (X - np.percentile(X, 1)) / (np.percentile(X, 99) - np.percentile(X, 1))\n",
      "  0%|                                                                                          | 0/961 [00:00<?, ?it/s]C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\torch\\nn\\functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "  2%|█▉                                                                               | 23/961 [00:10<06:28,  2.41it/s]C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\utils.py:334: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  X = (X - np.percentile(X, 1)) / (np.percentile(X, 99) - np.percentile(X, 1))\n",
      "C:\\Users\\lukasvandenheu\\Anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\utils.py:334: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = (X - np.percentile(X, 1)) / (np.percentile(X, 99) - np.percentile(X, 1))\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 961/961 [06:46<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: running network 280.49s; flow+mask computation 123.65\n",
      "estimated masks for 961 image(s) in 417.29 sec\n",
      ">>>> TOTAL TIME 417.29 sec\n",
      "Aligning patches in column  0 ...\n",
      "Aligning patches in column  1 ...\n",
      "Aligning patches in column  2 ...\n",
      "Aligning patches in column  3 ...\n",
      "Aligning patches in column  4 ...\n",
      "Aligning patches in column  5 ...\n",
      "Aligning patches in column  6 ...\n",
      "Aligning patches in column  7 ...\n",
      "Aligning patches in column  8 ...\n",
      "Aligning patches in column  9 ...\n",
      "Aligning patches in column  10 ...\n",
      "Aligning patches in column  11 ...\n",
      "Aligning patches in column  12 ...\n",
      "Aligning patches in column  13 ...\n",
      "Aligning patches in column  14 ...\n",
      "Aligning patches in column  15 ...\n",
      "Aligning patches in column  16 ...\n",
      "Aligning patches in column  17 ...\n",
      "Aligning patches in column  18 ...\n",
      "Aligning patches in column  19 ...\n",
      "Aligning patches in column  20 ...\n",
      "Aligning patches in column  21 ...\n",
      "Aligning patches in column  22 ...\n",
      "Aligning patches in column  23 ...\n",
      "Aligning patches in column  24 ...\n",
      "Aligning patches in column  25 ...\n",
      "Aligning patches in column  26 ...\n",
      "Aligning patches in column  27 ...\n",
      "Aligning patches in column  28 ...\n",
      "Aligning patches in column  29 ...\n",
      "Aligning patches in column  30 ...\n",
      "Aligning columns  0  and  2 ...\n",
      "Aligning columns  2  and  4 ...\n",
      "Aligning columns  4  and  6 ...\n",
      "Aligning columns  6  and  8 ...\n",
      "Aligning columns  8  and  10 ...\n",
      "Aligning columns  10  and  12 ...\n",
      "Aligning columns  12  and  14 ...\n",
      "Aligning columns  14  and  16 ...\n",
      "Aligning columns  16  and  18 ...\n",
      "Aligning columns  18  and  20 ...\n",
      "Aligning columns  20  and  22 ...\n",
      "Aligning columns  22  and  24 ...\n",
      "Aligning columns  24  and  26 ...\n",
      "Aligning columns  26  and  28 ...\n",
      "Aligning columns  28  and  30 ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filtered_fused_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b882223349e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwell_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwell\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_fused_mask.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_fused_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_fused_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_fused_mask' is not defined"
     ]
    }
   ],
   "source": [
    "# experiment = 'WKS024'\n",
    "# magnification = '10x'\n",
    "import os\n",
    "\n",
    "well = 'B02'\n",
    "root = r'M:\\tnw\\bn\\dm\\Shared\\Lukas\\NetworkAnalysis\\CellContactNetwork\\Cellpose'\n",
    "well_folder = os.path.join(root,well)\n",
    "[patch_height, patch_width] = [512,512]\n",
    "edge_thickness = 60 # pixels\n",
    "similarity_threshold = 0.8\n",
    "cell_size_threshold = 100 # minimal cell size in pixels\n",
    "\n",
    "# Cellpose parameters\n",
    "# DEFINE CELLPOSE MODEL\n",
    "# model_type='cyto' or model_type='nuclei'\n",
    "\n",
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "# channels = [0,0]\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "# channels = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "# channels = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "# channels = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "# or if you have different types of channels in each image\n",
    "# channels = [[2,3], [0,0], [0,0]]\n",
    "\n",
    "# if diameter is set to None, the size of the cells is estimated on a per image basis\n",
    "# you can set the average cell `diameter` in pixels yourself (recommended) \n",
    "# diameter can be a list or a single number for all images\n",
    "# ---------------------------------------------------------------------------------\n",
    "diameter = 97\n",
    "channels = [1,2] # R=cytoplasm and G=nucleus\n",
    "\n",
    "segmented = segment_fused_image_with_cellpose(root, well, diameter, channels,\n",
    "                                              edge_thickness=edge_thickness, similarity_threshold=similarity_threshold,\n",
    "                                              cell_size_threshold=cell_size_threshold, patch_height=patch_height, patch_width=patch_width)\n",
    "\n",
    "output_path = os.path.join(well_folder, well+'_fused_mask.tif')\n",
    "io.imshow(segmented)\n",
    "io.imsave(output_path, segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make naive fused mask (for debugging)\n",
    "M,N,C = np.shape(new_fused)\n",
    "fused_mask_naive = np.zeros((M,N))\n",
    "\n",
    "[m,n] = [patch_height, patch_width]\n",
    "\n",
    "for nn in range(0,num_patches_nn,2):\n",
    "    \n",
    "    c_n = patch_locations[1][nn]\n",
    "    \n",
    "    for mm in range(0,num_patches_mm,2):\n",
    "        c_m = patch_locations[0][mm]\n",
    "        nr = nn * num_patches_mm + mm\n",
    "        fused_mask_naive[c_m:c_m+m, c_n:c_n+n] = mask_list[nr]\n",
    "        \n",
    "\n",
    "io.imsave(well+'_fused_mask_naive.tif', fused_mask_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(aligned_columns[7][2200:2600,:])\n",
    "#io.imshow(aligned_columns[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(overlapping_columns[14][2200:2600,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(overlapping_columns[15][2200:2600,:],cmap='flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch1 = np.copy(overlapping_columns[14])      # left column\n",
    "patch2 = np.copy(overlapping_columns[16])    # right column\n",
    "patch_ol = np.copy(overlapping_columns[15])  # overlapping column\n",
    "edge_thickness = 60\n",
    "# Align patch1 and patch2 using overlap\n",
    "patch1_new,patch2_new = align_patches(patch1, patch2, patch_ol, edge_thickness, similarity_threshold, axis=1)\n",
    "\n",
    "#aligned_columns[-1] = patch1_new    # overwrite left column\n",
    "#aligned_columns.append(patch2_new)  # append right column\n",
    "\n",
    "io.imshow(patch1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-connecticut",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
